================================================================================
RANDOM FOREST SCALING LAWS ANALYSIS REPORT
================================================================================

DATA SCALING ANALYSIS
----------------------------------------

N Samples Train:
  • training_time: O(x^0.11) - Strong fit (R² = 0.994)
    Training time scales as O(n^0.11) with sample size (efficient scaling)
  • prediction_time: O(x^-0.82) - Strong fit (R² = 0.999)
    Prediction time scales as O(n^-0.82) with training sample size (efficient scaling)
  • training_memory_mb: O(x^0.01) - Strong fit (R² = 0.710)
    Memory usage scales as O(n^0.01) with sample size (efficient scaling)
  • prediction_memory_mb: O(x^0.01) - Strong fit (R² = 0.740)
    prediction_memory_mb scales as n_samples_train^0.01 (efficient scaling)

N Features:
  • training_time: O(x^-0.01) - Weak fit (R² = 0.003)
  • prediction_time: O(x^-0.00) - Weak fit (R² = 0.000)
  • training_memory_mb: O(x^0.00) - Weak fit (R² = 0.259)
  • prediction_memory_mb: O(x^0.00) - Weak fit (R² = 0.218)

PARAMETER SCALING ANALYSIS
----------------------------------------

N Estimators:
  • training_time: O(param^0.90) - Strong fit (R² = 0.998)
    Training time increases as O(trees^0.90)
  • prediction_time: O(param^0.00) - Weak fit (R² = 0.005)
    Prediction time increases as O(trees^0.00)
  • training_memory_mb: O(param^0.00) - Weak fit (R² = 0.333)
    Memory usage increases as O(trees^0.00)

Max Depth:

Min Samples Split:

Min Samples Leaf:

KEY INSIGHTS
----------------------------------------

• Scaling patterns appear reasonable for Random Forest models

================================================================================